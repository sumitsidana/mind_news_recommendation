{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import sys, os, os.path\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def dcg_score(y_true, y_score, k=10):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "    gains = 2 ** y_true - 1\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "    return np.sum(gains / discounts)\n",
    "    \n",
    "\n",
    "def ndcg_score(y_true, y_score, k=10):\n",
    "    best = dcg_score(y_true, y_true, k)\n",
    "    actual = dcg_score(y_true, y_score, k)\n",
    "    return actual / best\n",
    "\n",
    "\n",
    "def mrr_score(y_true, y_score):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order)\n",
    "    rr_score = y_true / (np.arange(len(y_true)) + 1)\n",
    "    return np.sum(rr_score) / np.sum(y_true)\n",
    "\n",
    "def parse_line(l):\n",
    "    impid, ranks = l.strip('\\n').split()\n",
    "    ranks = json.loads(ranks)\n",
    "    return impid, ranks\n",
    "\n",
    "def scoring(truth_f, sub_f):\n",
    "    aucs = []\n",
    "    mrrs = []\n",
    "    ndcg5s = []\n",
    "    ndcg10s = []\n",
    "    \n",
    "    line_index = 1\n",
    "    for lt in truth_f:\n",
    "        ls = sub_f.readline()\n",
    "        impid, labels = parse_line(lt)\n",
    "        \n",
    "        # ignore masked impressions\n",
    "        if labels == []:\n",
    "            continue \n",
    "        \n",
    "        if ls == '':\n",
    "            # empty line: filled with 0 ranks\n",
    "            sub_impid = impid\n",
    "            sub_ranks = [1] * len(labels)\n",
    "        else:\n",
    "            try:\n",
    "                sub_impid, sub_ranks = parse_line(ls)\n",
    "            except:\n",
    "                raise ValueError(\"line-{}: Invalid Input Format!\".format(line_index))       \n",
    "        \n",
    "        if sub_impid != impid:\n",
    "            raise ValueError(\"line-{}: Inconsistent Impression Id {} and {}\".format(\n",
    "                line_index,\n",
    "                sub_impid,\n",
    "                impid\n",
    "            ))        \n",
    "        \n",
    "        lt_len = float(len(labels))       \n",
    "        y_true =  np.array(labels,dtype='float32')\n",
    "        y_score = []\n",
    "        for rank in sub_ranks:\n",
    "            score_rslt = 1./rank\n",
    "            if score_rslt < 0 or score_rslt > 1:\n",
    "                raise ValueError(\"Line-{}: score_rslt should be int from 0 to {}\".format(\n",
    "                    line_index,\n",
    "                    lt_len\n",
    "                ))\n",
    "            y_score.append(score_rslt)\n",
    "            \n",
    "        auc = roc_auc_score(y_true,y_score)\n",
    "        mrr = mrr_score(y_true,y_score)\n",
    "        ndcg5 = ndcg_score(y_true,y_score,5)\n",
    "        ndcg10 = ndcg_score(y_true,y_score,10)\n",
    "        \n",
    "        aucs.append(auc)\n",
    "        mrrs.append(mrr)\n",
    "        ndcg5s.append(ndcg5)\n",
    "        ndcg10s.append(ndcg10)\n",
    "        \n",
    "        line_index += 1\n",
    "\n",
    "    return np.mean(aucs), np.mean(mrrs), np.mean(ndcg5s), np.mean(ndcg10s)\n",
    "        \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    input_dir = sys.argv[1]\n",
    "    output_dir = sys.argv[2]\n",
    "\n",
    "    submit_dir = os.path.join(input_dir, 'res') \n",
    "    truth_dir = los.path.join(input_dir, 'ref')\n",
    "\n",
    "    if not os.path.isdir(submit_dir):\n",
    "        print(\"%s doesn't exist\" % submit_dir)\n",
    "\n",
    "    if os.path.isdir(submit_dir) and os.path.isdir(truth_dir):\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        output_filename = os.path.join(output_dir, 'scores.txt')              \n",
    "        output_file = open(output_filename, 'w')\n",
    "\n",
    "        truth_file = open(os.path.join(truth_dir, \"truth.txt\"), 'r')\n",
    "        submission_answer_file = open(os.path.join(submit_dir, \"prediction.txt\"), 'r')\n",
    "        \n",
    "        auc, mrr, ndcg, ndcg10 = scoring(truth_file, submission_answer_file)\n",
    "\n",
    "        output_file.write(\"AUC:{:.4f}\\nMRR:{:.4f}\\nnDCG@5:{:.4f}\\nnDCG@10:{:.4f}\".format(auc, mrr, ndcg, ndcg10))\n",
    "        output_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
